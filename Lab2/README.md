# Детекция аномалий

Имеются изображения технологического процесса разлива металлических цилиндров. Есть риск нарушения технологии, когда стенки цилиндра не успевают застывать и трескаются. Незастывший металл выливается, не образуя требуемую заготовку. Необходимо оперативно определить лунку, где произошел пролив, при этом пролив довольно редкое явление, гораздо больше изображений можно собрать без пролива в лунке.

Задача: построить модель на основе автоэнкодера, определяющую состояние лунки: пролив\не пролив.

## Датесет
Данные - вырезанные с фото изображения лунок. [Ссылка на датасет](https://drive.google.com/file/d/1DHuQ3DBsgab6NtZIZfAKUHS2rW3-vmtb/view)
![img.png](img/img.png)

[//]: # (dataset)

[//]: # (├── proliv  # изображения с проливами)

[//]: # (|       ├── 000.jpg)

[//]: # (│       ├── 001.jpg)

[//]: # (│       │   └── ...)

[//]: # (|)

[//]: # (├── test  # тестовая выборка где перемешаны проливы и не_проливы)

[//]: # (│       ├── imgs)

[//]: # (│       │   ├── 000.jpg)

[//]: # (│       │   ├── 001.jpg)

[//]: # (│       │   └── ...)

[//]: # (│       └── test_annotation.txt)

[//]: # (|)

[//]: # (├── train  #  обучающая выборка из не_проливов)

[//]: # (|       ├── 000.jpg)

[//]: # (│       ├── 001.jpg)

[//]: # (│       └── ...)

## План решения

1. Имплементировать или найти автоэкодер 
2. Обучить автоэнкодер на не_проливах (dataset\train)
Если через такой автоэнкодер прогнать изображение пролива, то MSE между входным изображением и выходным будет больше, чем если прогнать изображение без пролива. Следовательно, если определить некторое пороговое значение MSE, можно классифицировать изображение на классы пролив\не_пролив. Если MSE между входной картинкой и выходной больше фиксированного порога, то на изображении пролив.
В качестве loss функции используем MSE (как минимум для baseline)
3. Написать метод классификации лунок в зависимости от порога
Для определения порога используем изображения из dataset\proliv
4. На изображениях из dataset\test протестировать качество: посчитать True_positive_rate и True_negative_rate (нужно получить более 91% по каждой).

## Решение и результаты

[Ссылка на решение](https://www.kaggle.com/code/anastasiiasemina1/anomaly-detection)

### Эксперимент 1

Обучен автоэнкодер, размерность латентного пространства - 2.

![img_6.png](img/img_6.png)

Я пробовала вручную выставлять 2 порога, при левом пороге 135 и правом 215 получились следующие метрики:

**TPR = 0.84, TNR = 0.84**. 

Неплохо, но нужно больше.

Далее я делала подбор левого порога в цикле с шагом 1, я поздно заметила, что проверка качества велась на тестовой выборке (а так считать нечестно), но даже на ней нужные метрики не достигаются:

![img_3.png](img/img_3.png)

Подбор правого порога с зафиксированным левым:

![img_2.png](img/img_2.png)
### Эксперимент 2

Еще пробовала обучать вариационный автоэнкодер с размерностью латентного пространства 2 и 100, но там получались примерно такие же распределения MSE и результаты.

![img_7.png](img/img_7.png)
![img_8.png](img/img_8.png)

## Следующие шаги
Основная проблема - это то, что между данными распределениями нет четкой границы.
Попробую еще доработать, добавлю аугментацию изображений, поменяю предобработку и возможно архитектуру автоэнкодера.